import torch
from pathlib import Path
from typing import Tuple
import gdown
import zipfile
from transformers import BertTokenizer, BertConfig


torch.backends.quantized.engine = "qnnpack"


# =========================
# ëª¨ë¸ ê²½ë¡œ
# =========================
BASE_DIR = Path(__file__).parent
MODEL_DIR = BASE_DIR / "models" / "my_korean_movie_sentiment_model"
MODEL_WEIGHTS = MODEL_DIR / "pytorch_model_quantized.pt"

_device = torch.device("cpu")
_model = None
_tokenizer = None


# =========================
# ëª¨ë¸ ë¡œë“œ (ë©”ëª¨ë¦¬ ìµœì í™”)
# =========================
def load_model():
    global _model, _tokenizer

    if _model is not None:
        return _model, _tokenizer

    print("ğŸ”„ ê°ì„±ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì¤‘...")

    try:
        # tokenizer ë¡œë“œ
        _tokenizer = BertTokenizer.from_pretrained(MODEL_DIR)

        # config ë¡œë“œ
        config = BertConfig.from_pretrained(
            MODEL_DIR,
            num_labels=3
        )

        # ëª¨ë¸ ë¡œë“œ
        _model = torch.load(
            MODEL_WEIGHTS,
            weights_only=False,
            map_location=_device
        )
        _model.to(_device)
        _model.eval()
        
        # ì¤‘ìš”: ê·¸ë˜ë””ì–¸íŠ¸ ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì ˆì•½)
        for param in _model.parameters():
            param.requires_grad = False
        
        # ë™ì  ì–‘ìí™” (ë©”ëª¨ë¦¬ 30% ê°ì†Œ)
        try:
            _model = torch.quantization.quantize_dynamic(
                _model,
                {torch.nn.Linear},
                dtype=torch.qint8
            )
            print("âœ… ë™ì  ì–‘ìí™” ì ìš©ë¨")
        except:
            print("âš ï¸ ì–‘ìí™” ì‹¤íŒ¨ (ëª¨ë¸ì´ ì´ë¯¸ ì–‘ìí™”ë˜ì—ˆì„ ìˆ˜ ìˆìŒ)")

        print("â˜‘ï¸ ê°ì„±ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        return _model, _tokenizer

    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None


# =========================
# ê°ì„± ì ìˆ˜ ê³„ì‚° (ê°œì„ ëœ ë¡œì§)
# =========================
def calculate_sentiment_score(neg: float, neu: float, pos: float) -> Tuple[str, float, float]:
    """
    ë” ì„¬ì„¸í•œ ê°ì„± ë¶„ì„ ë¡œì§
    """
    
    sorted_probs = sorted([pos, neg, neu], reverse=True)
    confidence_gap = sorted_probs[0] - sorted_probs[1]
    
    # 1. í™•ë¥ ì´ ê±°ì˜ ë¹„ìŠ·í•œ ê²½ìš° â†’ ì¤‘ë¦½
    if confidence_gap < 0.1:
        label = "ì¤‘ë¦½"
        confidence = neu
        sentiment_score = 2.5
    
    # 2. ì¤‘ë¦½ì´ ê°€ì¥ ë†’ì€ ê²½ìš°
    elif neu >= pos and neu >= neg:
        label = "ì¤‘ë¦½"
        confidence = neu
        sentiment_score = 2.5
    
    # 3. ê¸ì •ì´ ëª…í™•í•œ ê²½ìš°
    elif pos >= neg and pos > neu and pos >= 0.4:
        label = "ê¸ì •"
        confidence = pos
        sentiment_score = 3.0 + (pos - 0.4) / 0.6 * 2.0
    
    # 4. ë¶€ì •ì´ ëª…í™•í•œ ê²½ìš°
    elif neg >= pos and neg > neu and neg >= 0.4:
        label = "ë¶€ì •"
        confidence = neg
        sentiment_score = 2.0 - (neg - 0.4) / 0.6 * 1.0
    
    # 5. ê¸ì •ì´ ì•½í•œ ê²½ìš°
    elif pos >= neg and pos > neu and pos >= 0.3:
        label = "ì•½ê¸ì •"
        confidence = pos
        sentiment_score = 2.75 + (pos - 0.3) / 0.1 * 0.25
    
    # 6. ë¶€ì •ì´ ì•½í•œ ê²½ìš°
    elif neg >= pos and neg > neu and neg >= 0.3:
        label = "ì•½ë¶€ì •"
        confidence = neg
        sentiment_score = 2.25 - (neg - 0.3) / 0.1 * 0.25
    
    # 7. ê¸°íƒ€ ê²½ìš°
    else:
        label = "ì¤‘ë¦½"
        confidence = max(pos, neg, neu)
        sentiment_score = 2.5
    
    return label, confidence, sentiment_score


# =========================
# ê°ì„± ë¶„ì„ (ë©”ëª¨ë¦¬ ìµœì í™”)
# =========================
def analyze_sentiment(text: str) -> Tuple[str, float, float]:
    """
    ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ê°ì„±ë¶„ì„
    - í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
    - ë°°ì¹˜ ì²˜ë¦¬ ìµœì†Œí™”
    - ë©”ëª¨ë¦¬ ì •ë¦¬
    """
    model, tokenizer = load_model()

    if model is None:
        return "ì¤‘ë¦½", 0.5, 2.5

    try:
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ë©”ëª¨ë¦¬ ì ˆì•½)
        text = text[:256]  # 256 í† í°ìœ¼ë¡œ ì œí•œ
        
        inputs = tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            max_length=256,  # 512 â†’ 256ìœ¼ë¡œ ê°ì†Œ
            padding=True
        ).to(_device)

        # no_gradë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=-1)[0]

        neg, neu, pos = probs.tolist()

        # ê°œì„ ëœ ë¡œì§ ì‚¬ìš©
        label, confidence, sentiment_score = calculate_sentiment_score(neg, neu, pos)

        print(
            f"âœ“ ê°ì„±ë¶„ì„ | "
            f"NEG={neg:.3f} NEU={neu:.3f} POS={pos:.3f} â†’ {label} (ë³„ì : {sentiment_score:.2f}/5.0)"
        )

        return label, round(confidence, 3), round(sentiment_score, 2)

    except Exception as e:
        print(f":x: ê°ì„±ë¶„ì„ ì˜¤ë¥˜: {e}")
        return "ì¤‘ë¦½", 0.5, 2.5
    
    finally:
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        if 'inputs' in locals():
            del inputs
        torch.cuda.empty_cache()