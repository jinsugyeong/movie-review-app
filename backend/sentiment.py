import onnxruntime as ort
import numpy as np
from pathlib import Path
from typing import Tuple
from transformers import BertTokenizer
from huggingface_hub import snapshot_download

# =========================
# ëª¨ë¸ ê²½ë¡œ
# =========================
HF_REPO_ID = "jinsugyeong/korean_movie_onnx"
CACHE_DIR = Path("/tmp/onnx_model")  # Renderì—ì„œ ì•ˆì „

_session = None
_tokenizer = None


# =========================
# ëª¨ë¸ ë¡œë“œ (í•œ ë²ˆë§Œ ì‹¤í–‰)
# =========================
def load_model():
    global _session, _tokenizer

    if _session is not None:
        return _session, _tokenizer
    
    print("ğŸ”„ ê°ì„±ë¶„ì„ ONNX ëª¨ë¸ ë¡œë“œ ì‹œì‘")

    # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬
    if not (CACHE_DIR / "model.onnx").exists():
        print("ğŸ“¥ ëª¨ë¸ ìºì‹œ ì—†ìŒ â†’ ë‹¤ìš´ë¡œë“œ")
        snapshot_download(
            repo_id=HF_REPO_ID,
            local_dir=CACHE_DIR,
            local_dir_use_symlinks=False
        )
    else:
        print("â™»ï¸ ìºì‹œëœ ëª¨ë¸ ì‚¬ìš©")

    try:
        CACHE_DIR.mkdir(parents=True, exist_ok=True)

        # 1ï¸âƒ£ ë ˆí¬ ì „ì²´ ë‹¤ìš´ë¡œë“œ (model.onnx + model.onnx.data + tokenizer)
        local_repo_path = snapshot_download(
            repo_id=HF_REPO_ID,
            cache_dir=CACHE_DIR,
            local_dir_use_symlinks=False,  # âš  Renderì—ì„œ í•„ìˆ˜
        )

        # 2ï¸âƒ£ tokenizer ë¡œë“œ
        _tokenizer = BertTokenizer.from_pretrained(local_repo_path)

        # 3ï¸âƒ£ ONNX Runtime ì„¸ì…˜
        onnx_path = Path(local_repo_path) / "model.onnx"

        _session = ort.InferenceSession(
            str(onnx_path),
            providers=["CPUExecutionProvider"]
        )

        print("âœ… ê°ì„±ë¶„ì„ ONNX ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        return _session, _tokenizer

    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None



# =========================
# ê°ì„± ì ìˆ˜ ê³„ì‚°
# =========================
def calculate_sentiment_score(neg: float, neu: float, pos: float) -> Tuple[str, float, float]:
    """
    ê°ì„± ë¶„ì„ ë¡œì§ (ê¸ì •/ì¤‘ë¦½/ë¶€ì •)
    - ê¸ì •ê³¼ ë¶€ì •ì´ ëª¨ë‘ ë†’ìœ¼ë©´ ì¤‘ë¦½ìœ¼ë¡œ íŒë‹¨
    """
    
    sorted_probs = sorted([pos, neg, neu], reverse=True)
    confidence_gap = sorted_probs[0] - sorted_probs[1]
    
    # 1. ê¸ì •ê³¼ ë¶€ì •ì´ ëª¨ë‘ ë†’ì€ ê²½ìš° (í˜¼í•© ê°ì •) â†’ ì¤‘ë¦½
    # ì˜ˆ: "ì˜ìƒë¯¸ëŠ” ì¢‹ì§€ë§Œ ìŠ¤í† ë¦¬ê°€ ì•„ì‰½ë‹¤"
    if pos > 0.25 and neg > 0.25:
        label = "ì¤‘ë¦½"
        confidence = neu
        sentiment_score = 3.0
    
    # 2. í™•ë¥ ì´ ê±°ì˜ ë¹„ìŠ·í•œ ê²½ìš° â†’ ì¤‘ë¦½
    elif confidence_gap < 0.1:
        label = "ì¤‘ë¦½"
        confidence = neu
        sentiment_score = 2.5
    
    # 3. ì¤‘ë¦½ì´ ê°€ì¥ ë†’ì€ ê²½ìš°
    elif neu >= pos and neu >= neg:
        label = "ì¤‘ë¦½"
        confidence = neu
        sentiment_score = 3.0
    
    # 4. ê¸ì •ì´ ëª…í™•í•œ ê²½ìš°
    elif pos > neu and pos > neg:
        label = "ê¸ì •"
        confidence = pos
        # ê¸ì • í™•ë¥ ì— ë”°ë¼ 3.0 ~ 5.0 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§
        sentiment_score = 3.0 + (pos * 2.0)
    
    # 5. ë¶€ì •ì´ ëª…í™•í•œ ê²½ìš°
    elif neg > neu and neg > pos:
        label = "ë¶€ì •"
        confidence = neg
        # ë¶€ì • í™•ë¥ ì— ë”°ë¼ 1.0 ~ 2.0 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§
        sentiment_score = 2.5 - (neg * 1.0)
    
    # 6. ê¸°íƒ€ ê²½ìš°
    else:
        label = "ì¤‘ë¦½"
        confidence = max(pos, neg, neu)
        sentiment_score = 2.5
    
    return label, confidence, sentiment_score


# =========================
# ê°ì„± ë¶„ì„ (ONNX ì¶”ë¡ )
# =========================
def analyze_sentiment(text: str) -> Tuple[str, float, float]:
    """
    ONNX ëª¨ë¸ì„ ì‚¬ìš©í•œ ê°ì„±ë¶„ì„ + í‚¤ì›Œë“œ ê¸°ë°˜ ë³´ì •
    """
    session, tokenizer = load_model()

    if session is None:
        return "ì¤‘ë¦½", 0.5, 3.0

    try:
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ë©”ëª¨ë¦¬ ì ˆì•½)
        text = text[:256]
        
        # í† í¬ë‚˜ì´ì§•
        inputs = tokenizer(
            text,
            return_tensors="np",  # NumPy arrayë¡œ ë°˜í™˜
            truncation=True,
            max_length=256,
            padding="max_length"
        )

        # ONNX ì¶”ë¡ 
        ort_inputs = {
            "input_ids": inputs["input_ids"].astype(np.int64),
            "attention_mask": inputs["attention_mask"].astype(np.int64),
            "token_type_ids": inputs["token_type_ids"].astype(np.int64)
        }
        
        ort_outputs = session.run(None, ort_inputs)
        logits = ort_outputs[0][0]  # (batch_size, num_labels) â†’ (num_labels,)
        
        # Softmax ê³„ì‚°
        exp_logits = np.exp(logits - np.max(logits))
        probs = exp_logits / exp_logits.sum()
        
        neg, neu, pos = probs.tolist()
        
        # ===== í‚¤ì›Œë“œ ê¸°ë°˜ í˜¼í•© ê°ì • ë³´ì • =====
        
        # 1. ì—­ì ‘ ì ‘ì†ì‚¬
        contrast_keywords = [
            "í•˜ì§€ë§Œ", "ê·¸ëŸ¬ë‚˜", "ë‹¤ë§Œ", "ê·¸ëŸ°ë°", "ê·¼ë°", "BUT", "but",
            "ì˜¤íˆë ¤", "ë°˜ë©´", "ëŒ€ì‹ ", "ë¹„ë¡", "ë°˜ëŒ€ë¡œ", "ì•„ë‹ˆë¼"
        ]
        
        # 2. ê¸ì • í‚¤ì›Œë“œ
        positive_keywords = [
            "ì¢‹", "ìµœê³ ", "í›Œë¥­", "ë©‹ì§€", "ì™„ë²½", "ê°ë™", "ì¬ë°Œ", "ì¬ë¯¸",
            "í™”ë ¤", "ì••ë„", "ëŒ€ë‹¨", "ë©‹", "í™˜ìƒ", "ëë‚´ì£¼", "êµ¿", "ì¢‹ì•„",
            "ì¦", "ë§Œì¡±", "ì¶”ì²œ", "ë³¼ë§Œ", "ê´œì°®", "í›Œë¥­", "ëŒ€ë°•", "ì¬ë¯¸ìˆ",
            "ê°ëª…", "ì¸ìƒ", "ëª°ì…", "ìˆ˜ì‘", "ëª…ì‘", "ì¼í’ˆ", "ì˜ˆìˆ ", "íƒ„íƒ„", "ì§±"
        ]
        
        # 3. ê°•í•œ ë¶€ì • í‚¤ì›Œë“œ (ì´ê²ƒë“¤ì´ ë§ìœ¼ë©´ ë¬´ì¡°ê±´ ë¶€ì •)
        strong_negative_keywords = [
            "ì¡°ì¡", "ì¡¸ì‘", "ìµœì•…", "í˜•í¸ì—†", "ì“°ë ˆê¸°", "ë§ì‘", "ì‹¤íŒ¨",
            "ì§€ë£¨", "í•˜í’ˆ", "ì‚°ë§Œ", "ê±°ìŠ¬ë¦¬"
        ]
        
        # 4. ì¼ë°˜ ë¶€ì • í‚¤ì›Œë“œ
        negative_keywords = [
            "ì•„ì‰½", "ì•„ì‰¬ì›€", "ë‹¨ì ", "ë³„ë¡œ", "ì‹¤ë§", "ë¹„ìŠ·", "ë»”", 
            "ì•ˆ", "ëª»", "ì—†", "ë‚˜ì˜", "í‰ë²”", "ë¬´ë‚œ", "ê·¸ì €", "ê·¸ëƒ¥", "ê·¸ëŸ­ì €ëŸ­"
        ]
        
        # 5. ì¡°ê±´/ì–‘ë³´ í‘œí˜„
        conditional_keywords = [
            "~ë§Œ", "ì¡°ê¸ˆ", "ì•½ê°„", "ë‹¤ì†Œ", "ì–´ëŠì •ë„", "ë‚˜ë¦„"
        ]
        
        # í‚¤ì›Œë“œ ê°œìˆ˜ ì¹´ìš´íŠ¸ (ë¬¸ë§¥ ê³ ë ¤)
        strong_negative_count = sum(1 for keyword in strong_negative_keywords if keyword in text)
        positive_count = sum(1 for keyword in positive_keywords if keyword in text)
        negative_count = sum(1 for keyword in negative_keywords if keyword in text)
        
        has_contrast = any(keyword in text for keyword in contrast_keywords)
        has_conditional = any(keyword in text for keyword in conditional_keywords)
        
        # ===== ìš°ì„ ìˆœìœ„ íŒë‹¨ =====
        
        # 1. ê°•í•œ ë¶€ì • í‚¤ì›Œë“œê°€ 2ê°œ ì´ìƒì´ë©´ ë¬´ì¡°ê±´ ë¶€ì •ìœ¼ë¡œ ì²˜ë¦¬ (ë³´ì • ì•ˆí•¨)
        if strong_negative_count >= 2:
            # ëª¨ë¸ íŒë‹¨ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë³´ì •í•˜ì§€ ì•ŠìŒ)
            pass
        
        # 2. í˜¼í•© ê°ì • íŒ¨í„´ ê°ì§€
        else:
            is_mixed = False
            
            # íŒ¨í„´ 1: ì—­ì ‘ ì ‘ì†ì‚¬ ì¡´ì¬
            if has_contrast:
                is_mixed = True
            
            # íŒ¨í„´ 2: ê¸ì • + ë¶€ì • í‚¤ì›Œë“œ ë™ì‹œ ì¡´ì¬ (ê°œìˆ˜ë¡œ íŒë‹¨)
            if positive_count >= 1 and negative_count >= 1:
                # ë‹¨, ë¶€ì •ì´ ì••ë„ì ì´ë©´ í˜¼í•©ìœ¼ë¡œ ë³´ì§€ ì•ŠìŒ
                if negative_count + strong_negative_count > positive_count * 2:
                    is_mixed = False
                else:
                    is_mixed = True
            
            # íŒ¨í„´ 3: ì¡°ê±´ë¶€ í‘œí˜„ + (ê¸ì • ë˜ëŠ” ë¶€ì •)
            if has_conditional and (positive_count >= 1 or negative_count >= 1):
                is_mixed = True
            
            # í˜¼í•© ê°ì •ì´ ê°ì§€ë˜ë©´ í™•ë¥  ì¬ì¡°ì •
            if is_mixed:
                if pos > 0.6 or neg > 0.6:  # í•œìª½ì´ 60% ì´ìƒì´ë©´ ë³´ì •
                    neu = 0.5
                    pos = 0.3
                    neg = 0.2

        # ê°ì„± ì ìˆ˜ ê³„ì‚°
        label, confidence, sentiment_score = calculate_sentiment_score(neg, neu, pos)

        print(
            f"{text}\n"
            f"âœ“ ê°ì„±ë¶„ì„ | "
            f"NEG={neg:.3f} NEU={neu:.3f} POS={pos:.3f} â†’ {label} (ë³„ì : {sentiment_score:.2f})"
        )

        return label, round(confidence, 3), round(sentiment_score, 2)

    except Exception as e:
        print(f"âŒ ê°ì„±ë¶„ì„ ì˜¤ë¥˜: {e}")
        return "ì¤‘ë¦½", 0.5, 3.0