import torch
from pathlib import Path
from typing import Tuple
import gdown
import zipfile
from transformers import BertTokenizer, BertConfig


torch.backends.quantized.engine = "qnnpack"



# =========================
# ëª¨ë¸ ê²½ë¡œ
# =========================
BASE_DIR = Path(__file__).parent
MODEL_DIR = BASE_DIR / "models" / "korean_movie_sentiment_model"
MODEL_WEIGHTS = MODEL_DIR / "pytorch_model_quantized.pt"

_device = torch.device("cpu")

_model = None
_tokenizer = None


def download_and_extract_model():
    """Google Driveì—ì„œ ëª¨ë¸ í´ë”(ZIP) ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ"""
    if MODEL_WEIGHTS.exists():
        print("âœ… ëª¨ë¸ í´ë” ì´ë¯¸ ì¡´ì¬")
        return
    
    BASE_DIR.mkdir(parents=True, exist_ok=True)
    zip_path = BASE_DIR / "korean_movie_sentiment_model.zip"
    
    # Google Drive íŒŒì¼ ID (ìì‹ ì˜ IDë¡œ ë³€ê²½)
    FILE_ID = "YOUR_ZIP_FILE_ID_HERE"
    url = f"https://drive.google.com/uc?id={FILE_ID}"
    
    print("ğŸ“¥ Google Driveì—ì„œ ëª¨ë¸ í´ë” ë‹¤ìš´ë¡œë“œ ì¤‘...")
    gdown.download(url, str(zip_path), quiet=False)
    
    print("ğŸ“¦ ì••ì¶• í•´ì œ ì¤‘...")
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(BASE_DIR)
    
    # ZIP íŒŒì¼ ì‚­ì œ
    zip_path.unlink()
    print("âœ… ëª¨ë¸ í´ë” ì¤€ë¹„ ì™„ë£Œ!")



# =========================
# ëª¨ë¸ ë¡œë“œ (1íšŒ)
# =========================
def load_model():
    global _model, _tokenizer

    if _model is not None:
        return _model, _tokenizer

    print(":arrows_counterclockwise: ê°ì„±ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì¤‘...")

    try:
        # ëª¨ë¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ Google Driveì—ì„œ ë‹¤ìš´ë¡œë“œ
        download_and_extract_model()

        # :one: tokenizer ë¡œë“œ
        _tokenizer = BertTokenizer.from_pretrained(MODEL_DIR)

        # :two: config ì§ì ‘ ìƒì„± (ì¤‘ìš”)
        config = BertConfig.from_pretrained(
            MODEL_DIR,
            num_labels=3
        )

        # :three: ëª¨ë¸ êµ¬ì¡° ìƒì„± (from_pretrained :x:)
        _model = torch.load(
            MODEL_WEIGHTS,
            weights_only = False,
            map_location=_device
        )
        _model.to(_device)
        _model.eval()

        print(":white_check_mark: ê°ì„±ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        return _model, _tokenizer

    except Exception as e:
        print(f":x: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None


# =========================
# ê°ì„± ì ìˆ˜ ê³„ì‚° (ê°œì„ ëœ ë¡œì§)
# =========================
def calculate_sentiment_score(neg: float, neu: float, pos: float) -> Tuple[str, float, float]:
    """
    ë” ì„¬ì„¸í•œ ê°ì„± ë¶„ì„ ë¡œì§
    - í™•ë¥ ì˜ ì°¨ì´ë„ ê³ ë ¤
    - ì¤‘ë¦½ íŒì •ì˜ ëª…í™•í•œ ê¸°ì¤€
    - 0~5ì  ìŠ¤ì¼€ì¼ ë³€í™˜
    """
    
    # ê°ì •ë³„ ì°¨ì´ ê³„ì‚°
    pos_margin = pos - max(neg, neu)  # ê¸ì •ì´ ë‹¤ë¥¸ ê°ì •ë“¤ë³´ë‹¤ ì–¼ë§ˆë‚˜ ìš°ì›”í•œì§€
    neg_margin = neg - max(pos, neu)  # ë¶€ì •ì´ ë‹¤ë¥¸ ê°ì •ë“¤ë³´ë‹¤ ì–¼ë§ˆë‚˜ ìš°ì›”í•œì§€
    
    # ê°€ì¥ ë†’ì€ í™•ë¥ ê³¼ ë‘ ë²ˆì§¸ í™•ë¥ ì˜ ì°¨ì´
    sorted_probs = sorted([pos, neg, neu], reverse=True)
    confidence_gap = sorted_probs[0] - sorted_probs[1]
    
    # 1. í™•ë¥ ì´ ê±°ì˜ ë¹„ìŠ·í•œ ê²½ìš° â†’ ì¤‘ë¦½
    if confidence_gap < 0.1:  # 10% ì´ë‚´ ì°¨ì´
        label = "ì¤‘ë¦½"
        confidence = neu
        sentiment_score = 2.5  # 0~5ì  ì¤‘ ì •ì¤‘ì•™
    
    # 2. ì¤‘ë¦½ì´ ê°€ì¥ ë†’ì€ ê²½ìš°
    elif neu >= pos and neu >= neg:
        label = "ì¤‘ë¦½"
        confidence = neu
        sentiment_score = 2.5
    
    # 3. ê¸ì •ì´ ëª…í™•í•œ ê²½ìš° (pos >= 0.4)
    elif pos >= neg and pos > neu and pos >= 0.4:
        label = "ê¸ì •"
        confidence = pos
        # 0.4~1.0 ë²”ìœ„ë¥¼ 3~5ì ìœ¼ë¡œ ë§¤í•‘
        sentiment_score = 3.0 + (pos - 0.4) / 0.6 * 2.0
    
    # 4. ë¶€ì •ì´ ëª…í™•í•œ ê²½ìš° (neg >= 0.4)
    elif neg >= pos and neg > neu and neg >= 0.4:
        label = "ë¶€ì •"
        confidence = neg
        # 0.4~1.0 ë²”ìœ„ë¥¼ 1~1ì ìœ¼ë¡œ ë§¤í•‘
        sentiment_score = 2.0 - (neg - 0.4) / 0.6 * 1.0
    
    # 5. ê¸ì •ì´ ì•½í•œ ê²½ìš° (0.3~0.4)
    elif pos >= neg and pos > neu and pos >= 0.3:
        label = "ì•½ê¸ì •"
        confidence = pos
        sentiment_score = 2.75 + (pos - 0.3) / 0.1 * 0.25
    
    # 6. ë¶€ì •ì´ ì•½í•œ ê²½ìš° (0.3~0.4)
    elif neg >= pos and neg > neu and neg >= 0.3:
        label = "ì•½ë¶€ì •"
        confidence = neg
        sentiment_score = 2.25 - (neg - 0.3) / 0.1 * 0.25
    
    # 7. ê¸°íƒ€ ê²½ìš° (ë§¤ìš° ì•½í•œ ì‹ í˜¸)
    else:
        label = "ì¤‘ë¦½"
        confidence = max(pos, neg, neu)
        sentiment_score = 2.5
    
    return label, confidence, sentiment_score


# =========================
# ê°ì„± ë¶„ì„
# =========================
def analyze_sentiment(text: str) -> Tuple[str, float, float]:
    model, tokenizer = load_model()

    if model is None:
        return "ì¤‘ë¦½", 0.5, 2.5

    try:
        inputs = tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            max_length=512,
            padding=True
        ).to(_device)

        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=-1)[0]

        neg, neu, pos = probs.tolist()

        # ê°œì„ ëœ ë¡œì§ ì‚¬ìš©
        label, confidence, sentiment_score = calculate_sentiment_score(neg, neu, pos)

        print(
            f"âœ“ ê°ì„±ë¶„ì„ | "
            f"NEG={neg:.3f} NEU={neu:.3f} POS={pos:.3f} â†’ {label} (ë³„ì : {sentiment_score:.2f}/5.0)"
        )

        return label, round(confidence, 3), round(sentiment_score, 2)

    except Exception as e:
        print(f":x: ê°ì„±ë¶„ì„ ì˜¤ë¥˜: {e}")
        return "ì¤‘ë¦½", 0.5, 2.5